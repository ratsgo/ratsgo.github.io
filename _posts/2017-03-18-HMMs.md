---
title: Maximum Entropy Models, Hidden Markov Models
category: Machine Learning
tag: MEMs, HMMs
html header: <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"></script>
---

이번 포스팅에선 **최대엔트로피모델(Maximum Entropy Models)**과 **은닉마코프모델(Hidden Markov Models, HMMs)**을 다루어 보도록 하겠습니다. 둘 품사를 분류하는 **포스태깅** 등 단어의 연쇄로 나타나는 언어구조를 처리하는 데 쓰였던 기법입니다. 이 글은 고려대 산업경영공학부 강필성 교수님 강의와 서울대 언어학과 신효필 교수님 저서를 참고해 작성했음을 먼저 밝힙니다. 그럼 시작해보겠습니다.



## 최대엔트로피모델

**엔트로피(entropy)**란 어떤 대상이 지닌 정보량을 측정하는 기제입니다. 어떤 확률변수가 지니는 평균적인 불확실성(uncertainty)을 의미합니다. 최대엔트로피모델은 포스태깅에 적용돼 많은 관심을 받았는데요, 사실 자연언어처리 분야에서는 **다항로지스틱회귀(multinominal logistic regression)**를 최대엔트로피모델이라 부릅니다. 어떤 단어 C가 주어졌을 때 가장 확률이 높은 품사 t를 할당하는 최대엔트로피모델은 아래와 같이 수식화할 수 있습니다. (λi=로짓함수의 가중치, f=C에 해당하는 자질 벡터, Z=확률 합이 1이 되게 하는 정규화 인자)

$$P(t|C)=\frac { 1 }{ Z(C) } { exp( }\sum _{ i=1 }^{ n }{ { \lambda  }_{ i }{ f }_{ i } } )$$

그럼 위 모델을 바탕으로 실제 포스태깅을 하는 예시를 들어볼까요? '올림픽이 끝나고 난 뒤에'라는 구에서 중간에 나타나는 형태소인 '나'를 한번 포스태깅해보겠습니다. 세종코퍼스의 정답은 동사(VX)인데요. 이 '나'가 정답인 동사(VX)인지, 아니면 오답인 대명사(NP)로 태깅되는지 예측해보자는 거죠. 그래서 아래처럼 '나'는 아무것도 태깅되지 않은 '??'로 두었습니다.

> 올림픽/NNG 이/JKS 끝나/VV 고/EC 나/?? + ㄴ/ETM 뒤/NNG 에/JKB

최대엔트로피모델은 입력값으로 C에 해당하는 자질(f)들을 넣어 주어야 합니다. 이 자질들은 사람이 일일이 정해서 넣어주어야 합니다. 예컨대 C 단어에 해당하는 자질 벡터의 첫번째 요소는 '직전 형태소가 어미이면 1, 그렇지 않으면 0', 두번째 요소는 '해당 형태소가 어간이면 1, 아니면 0'... 이런 식으로 말입니다. 실제로 이 모델이 제안된 시기에는 자질 벡터의 요소를 조금 바꾸어 성능이 개선되면 논문이 될 정도였다고 합니다. 그만큼 특징/자질 추출에 사람 손을 많이 탔다는 이야기이죠.

어쨌든 자질 벡터의 각 요소를 모두 정하고 그 값 또한 구했다고 치고 해당 데이터로부터 다항로지스틱회귀의 파라메터(λi)를 찾으면 학습이 끝나게 됩니다. 학습 종료 후 예측을 하려면 우리가 품사 정보를 알고 싶은 '나'에 관련된 자질 벡터를 만들어주고 이를 다항로지스틱회귀 모델에 넣어서 가장 큰 확률값을 나타내주는 품사 t에 할당하면 됩니다. 예컨대 '나'의 자질벡터의 첫번째 요소는 1이겠네요. 직전에 등장하는 형태소가 어미(EC)이기 때문입니다. 이렇게 자질벡터를 입력값(X) 삼아 예측을 하는 구조입니다.



## 은닉마코프모델

**마코프모델**은 실제로 관찰될 수 있는 사건(event)들의 **연쇄(chain)**에 대한 확률을 계산하는 데 유용합니다. 그러나 사건들이 실제로는 관찰될 수 없는 경우가 많습니다. 단어 연쇄를 생각해볼까요? '나는 어제 학교에 갔다'라는 문장은 네 단어들의 연쇄로 되어 있지만 각 단어들이 어떤 품사로 되어 있는지는 즉, 단어들의 품사 연쇄는 직접적으로 관찰되지 않습니다. 이 때문에 은닉마코프모델은 단어들의 품사 정보가 **은닉(hidden)**되어 있다고 전제합니다. 바꿔 말하면 위 예시에서 '올림픽이 끝나고 난 뒤에'라는 단어들의 연쇄보다 아래와 같은 품사들의 연쇄정보가 먼저 있고, 실제 발화시 이 품사 연쇄정보에 맞는 단어가 **방출(emission)**된다고 가정하는 것이지요. 

> NNG ==> JKS ==> VV ==> EC ==> VX ==> ETM ==> NNG ==> JKB

자, 그럼 HMMs에 따라 실제로 품사를 예측해 볼까요? 단어 X가 주어졌을 때 품사 Y가 나타날 확률을 최대화하는 Y를 예측결과로 내놓는 아래와 같은 식을 만족해야 합니다.

$$
\begin{align*}
argmax_{ Y }{ P(Y|X) }&=argmax_{ Y }\frac { P(X|Y)P(Y) }{ P(X) } \\ 
&=argmax_{ Y }P(X|Y)P(Y)
\end{align*}
$$

여기서 P(Y)는 **전이확률(transition probability)**로서 단어들의 연쇄에서 이전 단어의 품사가 등장했을 때 다음 품사 Y로 전이할 확률을 말합니다. 위 시작상태에서 명사(NNG), 명사(NNG)에서 조사(JKS), 조사에서 어미(EC)... 이렇게 등장하는 모든 경우의 수를 전체 말뭉치에서 세어서 표로 만들어 놓는 것이죠. 대략 아래와 같은 경우가 될 겁니다.

|  구분  | NNG  | ...  |  VV  |
| :--: | :--: | :--: | :--: |
| NNG  | 0.1  | ...  | 0.2  |
| ...  | ...  | ...  | ...  |
|  VV  | 0.2  | ...  | 0.3  |

위 표를 해석하면 이렇습니다. 명사(NNG)가 나오고 그 다음 단어가 또 명사가 나올 확률은 0.1입니다. 전이확률도 확률값이므로 각 행이나 각 열의 합계는 1이 됩니다. 이 확률값들은 다시 한번 말씀드리지만 해당 케이스의 빈도를 전체 단어수로 나누어서 구한 것입니다.

P(X\|Y)는 **방출확률(emission)**로서 품사 정보 Y가 주어졌을 때 단어 X가 나타날 확률입니다. 히든마코프모델의 가정은 품사 정보가 이미 있고, 여기에 맞는 단어가 방출된다는 내용이기 때문에 방출확률이라는 이름이 붙은 것 같습니다. 어쨌든 방출확률은 품사 Y 가운데 단어 X의 빈도를 전체 말뭉치에서 일일이 세어서 구합니다. 예컨대 위 예시 기준으로 설명드리면 동사(VV)로 쓰인 '나'(여기서 주의할 점은 대명사로 쓰인 '나'는 빈도 체크에서 제외)가 얼마나 쓰였는지 세어서 확률값을 구한다는 겁니다.

결과적으로 우리가 어떤 단어 X가 주어졌을 때 품사 Y일 확률을 알고 싶다고 할 때 이미 말뭉치로부터 구해놓은 전이확률과 방출확률들을 참고해 Y의 모든 경우의 수를 대입해 확률값들을 구합니다. 이 확률값들 중 가장 높은 확률을 내어주는 Y로 X의 품사 분류를 하게 됩니다.



## 마코프가정과 HMMs

일부러 따로 설명드리려고 빼놓은 중요한 개념이 있습니다. 바로 **마코프 가정(Markov assumption)**인데요, 히든마코프모델은 이 가정에 기초하고 있습니다. 러시아 수학자 마코프가 1913년경에 러시아어 문헌에 나오는 글자들의 순서에 관한 모델을 구축하기 위해 제안된 개념입니다. 마코프 가정은 한 상태의 확률은 단지 그 이전 상태에만 의존한다는 것이 핵심입니다. 즉 한 상태에서 다른 상태로의 **전이(transition)**는 그동안 상태 전이에 대한 긴 이력(history)을 필요로 하지 않고 바로 직전 상태에서의 전이로 추정할 수 있다는 이야기입니다. 아래와 같이 도식화됩니다.

$$P({ q }_{ i }|{ q }_{ 1 },...,{ q }_{ i-1 })=P({ q }_{ i }|{ q }_{ i-1 })$$

그럼 이를 어떻게 이해할 수 있을까요? 한번 예를 들어보겠습니다. (품사로 예를 들어야 하는데 품사의 연쇄는 눈에 잘 들어오지 않아서 아래 문장으로 예시를 대체했습니다) '나는 어제 수학 공부를'라는 문장이 주어졌을 때 그 다음 단어가 '했다'가 나올 확률을 한번 계산해 보자는 겁니다. 그럼 아래와 같은 식이 될 겁니다. (C=괄호안에 있는 단어의 빈도)

$$P(했다|나는\quad어제\quad수학\quad공부를)=\frac { C(나는\quad어제\quad수학\quad공부를 \quad했다) }{ C(나는\quad 어제 \quad수학\quad공부를) } \quad $$

그런데 아시다시피 '나는 어제 수학 공부를'이라는 표현이 말뭉치에 정확하게 등장할 확률은 매우 낮을 겁니다. 단어들은 물론 그 표현도 매우 자유로운 게 자연언어의 속성이기 때문입니다. 하물며 '나는 어제 수학 공부를 했다'라는 표현은 어떻겠습니까. 따라서 현실적인 대안으로 아래처럼 처리를 합니다.

